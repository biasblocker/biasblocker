Bias Blocker is a collaborative project aimed at providing a self-help tool for journalists. Operating as an AI-based recommendation system, the Bias Blocker prototype detects, highlights, and corrects biased and discriminatory language within journalists' texts.
 
Our objective is to offer a mechanism for journalists striving to adopt inclusive language and to raise awareness of biased thinking when crafting sentences in both English and Arabic.
 
In Arabic, the tool is capable of identifying gendered bias, while the English version covers various bias categories, including gender, ethnicity, race, and politics.
 
The plugin was developed by a group of six individuals, comprising editors and technologists from Deutsche Welle, ABC News, and ARIJ. It was created as part of the AI Fellowship organized by PolisLSE. 

More at: 
- https://www.journalismai.info/festival
- https://blogs.lse.ac.uk/polis/2023/06/01/meet-the-2023-journalismai-fellowship-cohort/

In this Github account, you will find:
- The codebook
- The backend code
- Code and resource of our workshop paper which is accepted to appear at DELITE, co-located in COLING/LREC 2024.
